# Block AI Crawlers: https://github.com/ai-robots-txt/ai.robots.txt
{{ readFile "vendor/ai.robots.txt/robots.txt" }}

# Default rule
User-agent: *
Disallow:
Sitemap: {{ "sitemap.xml" | absURL }}
