<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Selfhosted on not just serendipity</title><link>https://www.perrotta.dev/tags/selfhosted/</link><description>Recent content in Selfhosted on not just serendipity</description><generator>Hugo -- 0.129.0</generator><language>en-us</language><copyright>Copyright © 2021 - 2024 Thiago Perrotta · CC BY-NC-SA 4.0 • RSS</copyright><lastBuildDate>Sun, 04 Feb 2024 23:27:09 -0300</lastBuildDate><atom:link href="https://www.perrotta.dev/tags/selfhosted/index.xml" rel="self" type="application/rss+xml"/><item><title>New domain</title><link>https://www.perrotta.dev/2024/02/new-domain/</link><pubDate>Sun, 04 Feb 2024 23:27:09 -0300</pubDate><guid>https://www.perrotta.dev/2024/02/new-domain/</guid><description>&lt;p>I got a new domain! This blog is now available on &lt;a href="https://www.perrotta.dev/">https://www.perrotta.dev/&lt;/a>.
There&amp;rsquo;s also a redirect to it from &lt;a href="https://blog.perrotta.dev/">https://blog.perrotta.dev/&lt;/a>.&lt;/p></description><content:encoded><![CDATA[<p>I got a new domain! This blog is now available on <a href="https://www.perrotta.dev/">https://www.perrotta.dev/</a>.
There&rsquo;s also a redirect to it from <a href="https://blog.perrotta.dev/">https://blog.perrotta.dev/</a>.</p>
<p>I don&rsquo;t know which one I like best, so <code>www</code> is the canonical subdomain for now.
Feel free to update the RSS in your feed reader, although
<a href="https://thiagowfx.github.io/">https://thiagowfx.github.io/</a> should keep working for a little longer, until (if
ever) I decide to migrate the static hosting off Github Pages.</p>
<p>This is a project I wanted to do since ages ago, and my goals go beyond merely
making my blog available under it. Stay tuned for more updates.</p>]]></content:encoded></item><item><title>WHOIS</title><link>https://www.perrotta.dev/2024/02/whois/</link><pubDate>Sun, 04 Feb 2024 00:20:15 -0300</pubDate><guid>https://www.perrotta.dev/2024/02/whois/</guid><description>&lt;p>I got myself a brand new domain! As I play with it, expect documentation to
be added.&lt;/p>
&lt;p>&lt;strong>How to query the WHOIS for the domain?&lt;/strong>&lt;/p></description><content:encoded><![CDATA[<p>I got myself a brand new domain! As I play with it, expect documentation to
be added.</p>
<p><strong>How to query the WHOIS for the domain?</strong></p>
<ol>
<li>From the command line: <code>$ whois &lt;domain&gt;</code></li>
<li>From the registrar WHOIS, e.g. <a href="https://porkbun.com/whois">https://porkbun.com/whois</a>, <a href="https://www.gandi.net/en/domain/p/whois">https://www.gandi.net/en/domain/p/whois</a></li>
<li>From the registry WHOIS, e.g. <a href="https://lookup.icann.org/">https://lookup.icann.org/</a>, <a href="https://www.registry.google/whois-lookup/">https://www.registry.google/whois-lookup/</a></li>
</ol>
<p>It&rsquo;s a good idea to set up WHOIS privacy, so that your domain registration
details stay private. Some registrars such as Porkbun and NearlyFreeSpeech will
gladly offer an option for that, either for free or at a low cost, respectively.</p>]]></content:encoded></item><item><title>★ Integrating terraform with ansible</title><link>https://www.perrotta.dev/2024/02/integrating-terraform-with-ansible/</link><pubDate>Thu, 01 Feb 2024 14:02:28 -0300</pubDate><guid>https://www.perrotta.dev/2024/02/integrating-terraform-with-ansible/</guid><description>&lt;p>This post is a follow-up of &lt;a href="https://www.perrotta.dev/2024/01/terraforming-a-linode-hello-world/">Terraforming a Linode: hello world&lt;/a>.&lt;/p>
&lt;blockquote>
&lt;p>In a future post, we will continue from here by using Ansible to install and
set up Miniflux in our new Linode.&lt;/p>
&lt;/blockquote>
&lt;p>Before we extensively use Ansible to configure our VPS instance, first let&amp;rsquo;s
set up a basic integration between Terraform and Ansible.&lt;/p></description><content:encoded><![CDATA[<p>This post is a follow-up of <a href="https://www.perrotta.dev/2024/01/terraforming-a-linode-hello-world/">Terraforming a Linode: hello world</a>.</p>
<blockquote>
<p>In a future post, we will continue from here by using Ansible to install and
set up Miniflux in our new Linode.</p>
</blockquote>
<p>Before we extensively use Ansible to configure our VPS instance, first let&rsquo;s
set up a basic integration between Terraform and Ansible.</p>
<p>First of all, here&rsquo;s an overview of where I stopped last time. There were a
couple of lightweight modifications since then. I&rsquo;ll explain some of them
below.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-terraform" data-lang="terraform"><span style="display:flex;"><span><span style="color:#f92672">%</span> <span style="color:#a6e22e">cat</span> var<span style="color:#a6e22e">iables</span>.<span style="color:#a6e22e">tf</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">variable</span> <span style="color:#e6db74">&#34;github_username&#34;</span> {
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">type</span>    = <span style="color:#a6e22e">string</span>
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">default</span> = <span style="color:#e6db74">&#34;thiagowfx&#34;</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">
</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">variable</span> <span style="color:#e6db74">&#34;linode_hostname&#34;</span> {
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">type</span>    = <span style="color:#a6e22e">string</span>
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">default</span> = <span style="color:#e6db74">&#34;coruscant&#34;</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">
</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">variable</span> <span style="color:#e6db74">&#34;linode_region&#34;</span> {
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">type</span>    = <span style="color:#a6e22e">string</span>
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">default</span> = <span style="color:#e6db74">&#34;eu-central&#34;</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>All variables were moved to a <code>variables.tf</code> file. This is to follow standard
terraform
<a href="https://developer.hashicorp.com/terraform/language/modules/develop/structure">conventions</a>
/ recommendations for module structures. Furthermore, it becomes easier to
manage variables when they are all stored in a single place.</p>
<p>The main module file now looks like this:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-terraform" data-lang="terraform"><span style="display:flex;"><span><span style="color:#f92672">%</span> <span style="color:#a6e22e">cat</span> <span style="color:#a6e22e">main</span>.<span style="color:#a6e22e">tf</span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">terraform</span> {
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">required_providers</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">http</span> = {
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">source</span> = <span style="color:#e6db74">&#34;hashicorp/http&#34;</span>
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">linode</span> = {
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">source</span> = <span style="color:#e6db74">&#34;linode/linode&#34;</span>
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">
</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">provider</span> <span style="color:#e6db74">&#34;linode&#34;</span> {}
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">
</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">data</span> <span style="color:#e6db74">&#34;http&#34;</span> <span style="color:#e6db74">&#34;github_keys&#34;</span> {
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">url</span> = <span style="color:#e6db74">&#34;https://api.github.com/users/</span><span style="color:#e6db74">${</span>var.<span style="color:#a6e22e">github_username</span><span style="color:#e6db74">}</span><span style="color:#e6db74">/keys&#34;</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">locals</span> {
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">keys</span> = jsondecode(data.<span style="color:#a6e22e">http</span>.<span style="color:#a6e22e">github_keys</span>.<span style="color:#a6e22e">response_body</span>)[<span style="color:#f92672">*</span>].<span style="color:#a6e22e">key</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">
</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">resource</span> <span style="color:#e6db74">&#34;linode_instance&#34;</span> <span style="color:#e6db74">&#34;nanode&#34;</span> {
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">type</span>             = <span style="color:#e6db74">&#34;g6-nanode-1&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">image</span>            = <span style="color:#e6db74">&#34;linode/alpine3.19&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">label</span>            = var.<span style="color:#a6e22e">linode_hostname</span>
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">region</span>           = var.<span style="color:#a6e22e">linode_region</span>
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">authorized_keys</span>  = <span style="color:#a6e22e">local</span>.<span style="color:#a6e22e">keys</span>
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">backups_enabled</span>  = <span style="color:#e6db74">&#34;false&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">booted</span>           = <span style="color:#e6db74">&#34;true&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">watchdog_enabled</span> = <span style="color:#e6db74">&#34;true&#34;</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>I removed the token from the linode provider. Now it is supplied via the
<code>LINODE_TOKEN</code> environment variable. In order to automatically populate that
variable, I use <a href="https://www.perrotta.dev/2022/01/direnv-automate-your-environment-variables/"><code>direnv</code></a>. There&rsquo;s an <code>.envrc</code> file that provides its value, like so:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#75715e">#!/bin/sh
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#75715e"># terraform init</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>export LINODE_TOKEN<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;my-token-here&#34;</span>
</span></span></code></pre></div><p>I also created a repository for this project:
<a href="https://github.com/thiagowfx/knol">https://github.com/thiagowfx/knol</a>. That&rsquo;s enough for preliminaries, now let&rsquo;s
go back to Ansible.</p>
<p>The first component we&rsquo;ll need is an Ansible
<a href="https://docs.ansible.com/ansible/latest/inventory_guide/intro_inventory.html">inventory</a>
file, containing the IP address of the host we&rsquo;ll manage. It could look like
this:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-ini" data-lang="ini"><span style="display:flex;"><span><span style="color:#66d9ef">[all]</span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">1.2.3.4 ansible_user</span><span style="color:#f92672">=</span><span style="color:#e6db74">root</span>
</span></span></code></pre></div><p>&hellip;wherein <code>1.2.3.4</code> is the IP address of our VPS.</p>
<p>That said, due to the fact the VPS instance is created dynamically, maintaining
that IP address manually would be tedious. Therefore, let&rsquo;s have Terraform
manage it.</p>
<p>We can do so with a
<a href="https://registry.terraform.io/providers/hashicorp/local/latest/docs/resources/file"><code>local_file</code></a>.
Heck, we could even use a
<a href="https://registry.terraform.io/providers/hashicorp/template/latest/docs/data-sources/file"><code>template_file</code></a>,
however it would be overkill as there are only two simple lines in our
inventory at this point. A <code>local_file</code> is created upon <code>terraform apply</code> and
deleted upon <code>terraform destroy</code>. Therefore it doesn&rsquo;t even need to be tracked
by our VCS:</p>
<pre tabindex="0"><code>resource &#34;local_file&#34; &#34;ansible_inventory&#34; {
  content  = &lt;&lt;-EOF
[all]
${linode_instance.nanode.ip_address} ansible_user=root
EOF
  filename = &#34;inventory.ini&#34;
  file_permission = &#34;0644&#34;
}
</code></pre><p>Once we run terraform (plan + apply), an <code>inventory.ini</code> file should be created
with the above contents.</p>
<p>Because the IP address is ephemeral and dynamic, we should have a
straightforward way to see its value. A terraform
<a href="https://developer.hashicorp.com/terraform/language/values/outputs"><code>output</code></a>
is perfect for that:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-terraform" data-lang="terraform"><span style="display:flex;"><span><span style="color:#f92672">%</span> <span style="color:#a6e22e">cat</span> <span style="color:#a6e22e">outputs</span>.<span style="color:#a6e22e">tf</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">output</span> <span style="color:#e6db74">&#34;ip_address&#34;</span> {
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">value</span> = <span style="color:#a6e22e">linode_instance</span>.<span style="color:#a6e22e">nanode</span>.<span style="color:#a6e22e">ip_address</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Later on (after terraforming) we will be able to use <code>terraform output</code> to see
the server IP address.</p>
<p>We have the inventory file. Now we need a
<a href="https://docs.ansible.com/ansible/latest/playbook_guide/playbooks_intro.html">playbook</a>.
A playbook contains a sequence of tasks to be applied to our server.</p>
<p>Let&rsquo;s start with a basic playbook that just installs and starts <code>nginx</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">hosts</span>: <span style="color:#ae81ff">all</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">tasks</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">Install the web server (nginx)</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">community.general.apk</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">name</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">state</span>: <span style="color:#ae81ff">present</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">Start the web server</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">service</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">name</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">state</span>: <span style="color:#ae81ff">started</span>
</span></span></code></pre></div><p>Save this to a <code>playbook.yml</code> file.</p>
<p>After terraforming, we should now be able to run ansible:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>% ansible-playbook -i inventory.ini playbook.yml
</span></span></code></pre></div><p>In order to make this setup more ergonomic, let&rsquo;s create a <code>Makefile</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Makefile" data-lang="Makefile"><span style="display:flex;"><span>TERRAFORM <span style="color:#f92672">:=</span> terraform
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">all</span><span style="color:#f92672">:</span> terraform ansible
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">ansible</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>	ansible-playbook -i inventory.ini playbook.yml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">terraform</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">$(</span>TERRAFORM<span style="color:#66d9ef">)</span> init
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">$(</span>TERRAFORM<span style="color:#66d9ef">)</span> plan
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">$(</span>TERRAFORM<span style="color:#66d9ef">)</span> apply
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">clean</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">$(</span>TERRAFORM<span style="color:#66d9ef">)</span> destroy
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">.PHONY</span><span style="color:#f92672">:</span> all ansible terraform clean
</span></span></code></pre></div><p>Then we can just run <code>make terraform</code> or <code>make ansible</code> for granular steps. Or
just <code>make</code> to run everything in the right order.</p>
<p>I extracted the <code>terraform</code> binary to its own variable because it facilitates
the use of <a href="https://opentofu.org/">OpenTofu</a> (a fork) in lieu of terraform.</p>
<p>And that&rsquo;s it for today! In a future post, we&rsquo;ll look into extending our
Ansible usage to fully bootstrap Miniflux on the server.</p>]]></content:encoded></item><item><title>★ Terraforming a Linode: hello world</title><link>https://www.perrotta.dev/2024/01/terraforming-a-linode-hello-world/</link><pubDate>Tue, 23 Jan 2024 23:27:04 -0300</pubDate><guid>https://www.perrotta.dev/2024/01/terraforming-a-linode-hello-world/</guid><description>&lt;p>I host my own &lt;a href="https://miniflux.app/">Miniflux&lt;/a> instance, which happens to be
my favorite RSS reader. Currently it is hosted on Linode (Akamai Cloud)
running &lt;a href="https://www.alpinelinux.org/">Alpine Linux&lt;/a>.&lt;/p>
&lt;p>My current setup was performed manually. I was thinking that, for fun, it would
be cool to fully automate it under the principles of
&lt;a href="https://en.wikipedia.org/wiki/Infrastructure_as_code">IaC&lt;/a>.&lt;/p></description><content:encoded><![CDATA[<p>I host my own <a href="https://miniflux.app/">Miniflux</a> instance, which happens to be
my favorite RSS reader. Currently it is hosted on Linode (Akamai Cloud)
running <a href="https://www.alpinelinux.org/">Alpine Linux</a>.</p>
<p>My current setup was performed manually. I was thinking that, for fun, it would
be cool to fully automate it under the principles of
<a href="https://en.wikipedia.org/wiki/Infrastructure_as_code">IaC</a>.</p>
<p>The current setup does not use any containers. I had proudly made it as KISS as
possible at the time:</p>
<ol>
<li>Linode is a very beginner-friendly (and cheap) VPS</li>
<li>Alpine Linux is a first-class citizen on Linode</li>
<li>There&rsquo;s an <code>apk</code> <a href="https://pkgs.alpinelinux.org/packages?name=miniflux">package</a> for <code>miniflux</code></li>
<li>There&rsquo;s an OpenRC<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> script for <code>miniflux</code> (so that it can be controlled via <code>service</code>)</li>
</ol>
<p>For the first part of this automation we will look into provisioning a Linode
with an Alpine Linux installation. In order to do so we will use HashiCorp
<a href="https://www.terraform.io/">Terraform</a>.</p>
<h2 id="requirements">Requirements</h2>
<ul>
<li>Provision a new Linode</li>
<li>Deploy it in Europe</li>
<li>Use the smallest shape (a so-called <a href="https://www.linode.com/community/questions/211/what-is-a-nanode">Nanode</a>)</li>
<li>Run Alpine Linux</li>
<li>Set it up with my <a href="https://github.com/thiagowfx.keys">public ssh key</a>, which is hosted on Github</li>
</ul>
<h2 id="terraform-setup">Terraform setup</h2>
<ul>
<li>Install a provider for Linode: <a href="https://registry.terraform.io/providers/linode/linode/latest/docs">https://registry.terraform.io/providers/linode/linode/latest/docs</a></li>
</ul>
<p>Scaffold it like this, in a <code>main.tf</code> file:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-terraform" data-lang="terraform"><span style="display:flex;"><span><span style="color:#a6e22e">terraform</span> {
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">required_providers</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">linode</span> = {
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">source</span> = <span style="color:#e6db74">&#34;linode/linode&#34;</span>
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Then run:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>% terraform init
</span></span></code></pre></div><ul>
<li>Generate a Linode API token</li>
</ul>
<p>Go to <a href="https://cloud.linode.com/profile/tokens">https://cloud.linode.com/profile/tokens</a>, create a new token called
<code>terraform</code>. with the &ldquo;Linodes&rdquo; scope set to &ldquo;Read/Write&rdquo;.</p>
<ul>
<li>Append this API token to <code>main.tf</code>:</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-terraform" data-lang="terraform"><span style="display:flex;"><span><span style="color:#66d9ef">provider</span> <span style="color:#e6db74">&#34;linode&#34;</span> {
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">token</span> = <span style="color:#e6db74">&#34;&lt;your token here&gt;&#34;</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><ul>
<li>Add a
<a href="https://registry.terraform.io/providers/linode/linode/latest/docs/resources/instance"><code>linode_instance</code></a>
with the appropriate fields set according to the documentation:</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-terraform" data-lang="terraform"><span style="display:flex;"><span><span style="color:#66d9ef">resource</span> <span style="color:#e6db74">&#34;linode_instance&#34;</span> <span style="color:#e6db74">&#34;coruscant&#34;</span> {
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">label</span>  = <span style="color:#e6db74">&#34;coruscant&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">image</span>  = <span style="color:#e6db74">&#34;linode/alpine3.19&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">region</span> = <span style="color:#e6db74">&#34;eu-central&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">type</span>   = <span style="color:#e6db74">&#34;g6-nanode-1&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">authorized_keys</span>  = [<span style="color:#e6db74">&#34;&lt;your ssh public key here&gt;&#34;</span>]
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">backups_enabled</span>  = <span style="color:#e6db74">&#34;false&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">watchdog_enabled</span> = <span style="color:#e6db74">&#34;true&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">booted</span>           = <span style="color:#e6db74">&#34;true&#34;</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Then run:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>% terraform plan
</span></span></code></pre></div><p>&ldquo;Plan&rdquo; is basically a dry-run. Terraform will output what it intends to do, but nothing will be done yet.</p>
<ul>
<li>Analyze the output and double check that it looks correct.</li>
</ul>
<p>To actually perform the provisioning, run:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>% terraform apply
</span></span></code></pre></div><p>Then confirm the prompt.</p>
<p>Within a few seconds (or maybe minutes), you should see your new Linode in the
<a href="https://cloud.linode.com/">Linode Console</a>.</p>
<p>We can test our deployment by ssh&rsquo;ing to our new machine:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>% ssh root@&lt;public IP address&gt; -i ~/.ssh/my_ssh_key
</span></span><span style="display:flex;"><span>Welcome to Alpine!
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>The Alpine Wiki contains a large amount of how-to guides and general
</span></span><span style="display:flex;"><span>information about administrating Alpine systems.
</span></span><span style="display:flex;"><span>See &lt;https://wiki.alpinelinux.org/&gt;.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>You can setup the system with the command: setup-alpine
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>You may change this message by editing /etc/motd.
</span></span></code></pre></div><p>Let&rsquo;s take a pause to appreciate how lightweight it is:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>localhost:~# df -h
</span></span><span style="display:flex;"><span>Filesystem                Size      Used Available Use% Mounted on
</span></span><span style="display:flex;"><span>devtmpfs                 10.0M         <span style="color:#ae81ff">0</span>     10.0M   0% /dev
</span></span><span style="display:flex;"><span>shm                     487.8M         <span style="color:#ae81ff">0</span>    487.8M   0% /dev/shm
</span></span><span style="display:flex;"><span>/dev/sda                 24.1G    238.1M     22.6G   1% /
</span></span><span style="display:flex;"><span>tmpfs                   195.1M    268.0K    194.8M   0% /run
</span></span></code></pre></div><p>Only 238 MiB!</p>
<p>To deprovision it, run:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>% terraform plan -destroy
</span></span></code></pre></div><p>If everything looks correct, run:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>% terraform destroy
</span></span></code></pre></div><p><strong>Warning</strong>: It turns out the &ldquo;Linodes&rdquo; scope was not enough to do the
deprovisioning. I needed to create a new scope, with more permissions, in order
to do so.</p>
<p>As you can see, terraform makes it very trivial to deprovision systems.</p>
<p><strong>Bonus points</strong>: run <code>terraform fmt</code> to format your file. Never go <a href="https://www.youtube.com/watch?v=-CmadmM5cOk">out of
style</a>.</p>
<p><strong>Tip</strong>: At any point you can run <code>terraform validate</code> to verify your <code>main.tf</code>
file is syntactically correct.</p>
<p>Two things could be improved in the previous setup:</p>
<ul>
<li>We could use <code>authorized_users</code> to pass in our linode username. If we add an
SSH key to our linode account, then that key would be automatically deployed
to the system, thereby removing the need to specify <code>authorized_keys</code>.</li>
<li>Alternatively, we could fetch our key from an URL endpoint with the use of
the <code>hashicorp/http</code> provider, like so:</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-terraform" data-lang="terraform"><span style="display:flex;"><span><span style="color:#a6e22e">terraform</span> {
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">required_providers</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">http</span> = {
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">source</span> = <span style="color:#e6db74">&#34;hashicorp/http&#34;</span>
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">
</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">data</span> <span style="color:#e6db74">&#34;http&#34;</span> <span style="color:#e6db74">&#34;thiagowfx_ssh_keys&#34;</span> {
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">url</span> = <span style="color:#e6db74">&#34;https://github.com/thiagowfx.keys&#34;</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">
</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">resource</span> <span style="color:#e6db74">&#34;linode_instance&#34;</span> <span style="color:#e6db74">&#34;coruscant&#34;</span> {<span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">  # ...
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#a6e22e">authorized_keys</span>  = compact([<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">line</span> <span style="color:#66d9ef">in</span> split(<span style="color:#e6db74">&#34;</span><span style="color:#960050;background-color:#1e0010">\</span><span style="color:#e6db74">n&#34;</span>, data.<span style="color:#a6e22e">http</span>.<span style="color:#a6e22e">thiagowfx_ssh_keys</span>.<span style="color:#a6e22e">response_body</span>) <span style="color:#f92672">:</span> chomp(<span style="color:#a6e22e">line</span>)])<span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">  # ...
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>}
</span></span></code></pre></div><p>The &ldquo;list comprehension&rdquo; above does line splitting magic to convert them to a
list of string, and the <code>compact</code> removes the empty new line at the end.</p>
<p>We could improve the example above even further.</p>
<p>For starters, let&rsquo;s parameterize out the username to a variable:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-terraform" data-lang="terraform"><span style="display:flex;"><span><span style="color:#66d9ef">variable</span> <span style="color:#e6db74">&#34;github_username&#34;</span> {
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">type</span>    = <span style="color:#a6e22e">string</span>
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">default</span> = <span style="color:#e6db74">&#34;thiagowfx&#34;</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">
</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">data</span> <span style="color:#e6db74">&#34;http&#34;</span> <span style="color:#e6db74">&#34;user_ssh_keys&#34;</span> {
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">url</span> = <span style="color:#e6db74">&#34;https://github.com/</span><span style="color:#e6db74">${</span>var.<span style="color:#a6e22e">github_username</span><span style="color:#e6db74">}</span><span style="color:#e6db74">.keys&#34;</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">
</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">resource</span> <span style="color:#e6db74">&#34;linode_instance&#34;</span> <span style="color:#e6db74">&#34;coruscant&#34;</span> {<span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">  # ...
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#a6e22e">authorized_keys</span>  = compact([<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">line</span> <span style="color:#66d9ef">in</span> split(<span style="color:#e6db74">&#34;</span><span style="color:#960050;background-color:#1e0010">\</span><span style="color:#e6db74">n&#34;</span>, data.<span style="color:#a6e22e">http</span>.<span style="color:#a6e22e">user_ssh_keys</span>.<span style="color:#a6e22e">response_body</span>) <span style="color:#f92672">:</span> chomp(<span style="color:#a6e22e">line</span>)])<span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">  # ...
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>}
</span></span></code></pre></div><p>We could then easily supply another username with <code>-var</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>% terraform plan -var github_username<span style="color:#f92672">=</span>torvalds
</span></span></code></pre></div><p>Note that the above example leverages <a href="https://developer.hashicorp.com/terraform/language/expressions/strings">string interpolation</a>.</p>
<p>We could also extract the SSH keys list to its own &ldquo;variable&rdquo; (<a href="https://developer.hashicorp.com/terraform/language/values/locals">locals</a>):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-terraform" data-lang="terraform"><span style="display:flex;"><span><span style="color:#a6e22e">locals</span> {
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">ssh_keys</span> = compact([<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">line</span> <span style="color:#66d9ef">in</span> split(<span style="color:#e6db74">&#34;</span><span style="color:#960050;background-color:#1e0010">\</span><span style="color:#e6db74">n&#34;</span>, data.<span style="color:#a6e22e">http</span>.<span style="color:#a6e22e">user_ssh_keys</span>.<span style="color:#a6e22e">response_body</span>) <span style="color:#f92672">:</span> chomp(<span style="color:#a6e22e">line</span>)])
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">
</span></span></span><span style="display:flex;"><span><span style="color:#66d9ef">resource</span> <span style="color:#e6db74">&#34;linode_instance&#34;</span> <span style="color:#e6db74">&#34;coruscant&#34;</span> {<span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">  # ...
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#a6e22e">authorized_keys</span>  = <span style="color:#a6e22e">local</span>.<span style="color:#a6e22e">ssh_keys</span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">  # ...
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>}
</span></span></code></pre></div><p>A more robust (and stable) way to query the key though is through the Github API:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-terraform" data-lang="terraform"><span style="display:flex;"><span><span style="color:#66d9ef">data</span> <span style="color:#e6db74">&#34;http&#34;</span> <span style="color:#e6db74">&#34;github_keys&#34;</span> {
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">url</span> = <span style="color:#e6db74">&#34;https://api.github.com/users/</span><span style="color:#e6db74">${</span>var.<span style="color:#a6e22e">github_username</span><span style="color:#e6db74">}</span><span style="color:#e6db74">/keys&#34;</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">locals</span> {
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">ssh_keys</span> = jsondecode(data.<span style="color:#a6e22e">http</span>.<span style="color:#a6e22e">github_keys</span>.<span style="color:#a6e22e">response_body</span>)[<span style="color:#f92672">*</span>].<span style="color:#a6e22e">key</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Note that a typical response body looks like the following:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-json" data-lang="json"><span style="display:flex;"><span>[
</span></span><span style="display:flex;"><span>  {
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&#34;id&#34;</span>: <span style="color:#e6db74">&#34;&lt;id&gt;&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&#34;key&#34;</span>: <span style="color:#e6db74">&#34;&lt;ssh key&gt;&#34;</span>
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>]
</span></span></code></pre></div><p>API endpoint documentation:
<a href="https://docs.github.com/en/rest/users/keys?apiVersion=2022-11-28#list-public-keys-for-a-user">https://docs.github.com/en/rest/users/keys?apiVersion=2022-11-28#list-public-keys-for-a-user</a></p>
<p>If we use <code>output</code> instead of <code>locals</code>, then we can debug (inspect) it with
<code>terraform output</code>.</p>
<p>And that&rsquo;s it for today! In a future post, we will continue from here by using
<a href="https://www.ansible.com/">Ansible</a> to install and set up Miniflux in our new
Linode.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Alpine Linux does not use <code>systemd</code>.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>]]></content:encoded></item><item><title>RSS: bridging the gap</title><link>https://www.perrotta.dev/2022/02/rss-bridging-the-gap/</link><pubDate>Wed, 09 Feb 2022 22:17:52 -0500</pubDate><guid>https://www.perrotta.dev/2022/02/rss-bridging-the-gap/</guid><description>&lt;p>Not everything is available via RSS. However, there are some decent workarounds in a few situations.&lt;/p></description><content:encoded><![CDATA[<p>Not everything is available via RSS. However, there are some decent workarounds in a few situations.</p>
<h2 id="newsletters">Newsletters</h2>
<p>Some blogs and authors refuse to provide RSS feeds to their websites. Instead, they will only provide newsletters.
This is very hostile to the open web, and the main reason why it&rsquo;s done is so that these authors can own a direct channel to reach out to their audience directly,
which is better for (their) business, making it easier for them to push sponsored and promoted content and measure engagement metrics and analytics.</p>
<p><a href="https://kill-the-newsletter.com/">Kill the Newsletter</a> is a service that proxies those newsletters, publishing them as RSS feeds.</p>
<p>You can either <a href="https://github.com/leafac/kill-the-newsletter">self-host</a> it or use its official hosted version at <a href="https://kill-the-newsletter.com/">https://kill-the-newsletter.com/</a>.</p>
<h2 id="twitter">Twitter</h2>
<p>Use Nitter:</p>
<blockquote>
<p>Nitter is a free and open source alternative Twitter front-end focused on privacy. The source is available on GitHub at <a href="https://github.com/zedeus/nitter">https://github.com/zedeus/nitter</a></p>
</blockquote>
<p>Furthermore, it has built-in RSS support!</p>
<p>For example, you can see @taylorswift13&rsquo;s profile on Nitter at <a href="https://nitter.net/taylorswift13">https://nitter.net/taylorswift13</a>
and follow her via RSS with <a href="https://nitter.net/taylorswift13/rss">https://nitter.net/taylorswift13/rss</a> — by merely appending <code>/rss</code> to it.</p>
<p>You can either self-host it or use one of its <a href="https://github.com/zedeus/nitter/wiki/Instances">public instances</a>.
At the time of this writing the official instance is <a href="https://nitter.net">https://nitter.net</a>.</p>
<h2 id="reddit">Reddit</h2>
<p>Reddit famously includes RSS support for every subreddit, for example<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>: <a href="https://www.reddit.com/r/archlinux/.rss">https://www.reddit.com/r/archlinux/.rss</a>.
It has a lot of noise though as it includes all recent posts including the ones with a few number of votes.</p>
<p>To experience a higher quality, filtered version of the latest given subreddit posts with more than a certain threshold (of your choosing) of upvotes, check out the <a href="https://github.com/johnwarne/reddit-top-rss">reddit-top-rss</a> project:</p>
<blockquote>
<p>Reddit Top RSS is a set of scripts for Reddit&rsquo;s API that generates RSS feeds for specified subreddits with score thresholds. To preview your outputted feed items there is a front end that utilizes the Bootstrap v4 framework.</p>
</blockquote>
<p>You&rsquo;re supposed to self-host it, but there&rsquo;s a demo version available at <a href="https://reddit-top-rss.herokuapp.com/">https://reddit-top-rss.herokuapp.com/</a>.</p>
<h2 id="appendix">Appendix</h2>
<p>For more RSS bridges and resources, see:</p>
<ul>
<li><a href="https://github.com/RSS-Bridge/rss-bridge">https://github.com/RSS-Bridge/rss-bridge</a></li>
<li><a href="https://github.com/AboutRSS/ALL-about-RSS">https://github.com/AboutRSS/ALL-about-RSS</a></li>
</ul>
<p><strong>Disclaimer</strong>: I do not endorse these lists of resources. Use them at your own risk.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>The last slash isn&rsquo;t strictly necessary: <a href="https://www.reddit.com/r/archlinux.rss">https://www.reddit.com/r/archlinux.rss</a> is also valid.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>]]></content:encoded></item><item><title>Thoughts on Gemini</title><link>https://www.perrotta.dev/2022/02/thoughts-on-gemini/</link><pubDate>Tue, 08 Feb 2022 11:40:00 -0500</pubDate><guid>https://www.perrotta.dev/2022/02/thoughts-on-gemini/</guid><description>&lt;p>From the &lt;a href="https://gemini.circumlunar.space">homepage&lt;/a>:&lt;/p>
&lt;blockquote>
&lt;p>Gemini is a new internet protocol which:&lt;/p>
&lt;ul>
&lt;li>Is heavier than gopher&lt;/li>
&lt;li>Is lighter than the web&lt;/li>
&lt;li>Will not replace either&lt;/li>
&lt;li>Strives for maximum power to weight ratio&lt;/li>
&lt;li>Takes user privacy very seriously&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>That&amp;rsquo;s too abstract though. I prefer the way &lt;a href="https://kevq.uk/gemini-isnt-the-solution-to-the-broken-web/">Kev Quirk&lt;/a> puts it:&lt;/p>
&lt;blockquote>
&lt;p>To put that into human-digestible form; Gemini is basically a very light, text-only alternative to HTML.&lt;/p>
&lt;/blockquote></description><content:encoded><![CDATA[<p>From the <a href="https://gemini.circumlunar.space">homepage</a>:</p>
<blockquote>
<p>Gemini is a new internet protocol which:</p>
<ul>
<li>Is heavier than gopher</li>
<li>Is lighter than the web</li>
<li>Will not replace either</li>
<li>Strives for maximum power to weight ratio</li>
<li>Takes user privacy very seriously</li>
</ul>
</blockquote>
<p>That&rsquo;s too abstract though. I prefer the way <a href="https://kevq.uk/gemini-isnt-the-solution-to-the-broken-web/">Kev Quirk</a> puts it:</p>
<blockquote>
<p>To put that into human-digestible form; Gemini is basically a very light, text-only alternative to HTML.</p>
</blockquote>
<p>Gemini aims to replace &ldquo;lightweight HTML&rdquo;, but it already starts with a big barrier for entry and adoption: It&rsquo;s not obvious what it is by just reading its project homepage alone. This in my opinion comes off as elitist.</p>
<p>Furthermore, you need a custom piece of software in order to consume the so-called gemini <em>capsules</em> (a fancy name for what&rsquo;s the equivalent of a plain-text <a href="https://jamstack.org/generators/">SSG</a> website).</p>
<p>I tried out <a href="https://github.com/makeworld-the-better-one/amfora"><code>amfora</code></a> which is a popular CLI one<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. Amfora is pretty decent and lightweight. The experience is very similar to a hybrid of using a CLI RSS reader like <a href="https://newsboat.org"><code>newsboat</code></a> to keep track of your favorite capsules, and a CLI Web browser like <code>elinks</code> or <code>w3m</code> to navigate them.</p>
<p>And that&rsquo;s part of the adoption problem: Why would you subject yourself to purposely using a text-only browser in the 2020s? It is a painful experience, and there&rsquo;s not any extra value compared to just using a minimalist RSS reader like <a href="https://miniflux.app">miniflux</a> to keep track of your favorite blogs / news portals via RSS.</p>
<p>Nowadays there are plenty of SSGs, for every programming language you can think of, even in plain shell scripting (POSIX <code>sh</code>). There&rsquo;s little reason to learn a new niche protocol given that it&rsquo;s relatively easy to publish simple blogs.</p>
<p>Conclusion: As Kev puts it:</p>
<blockquote>
<p>I’m not sure if you heard, but <a href="https://thewebisfucked.com">The Web Is F*cked</a> and techies everywhere are touting the Gemini protocol as its saviour. I disagree. A lot.</p>
</blockquote>
<p>I will end this article with a praise for Gemini, courtesy of <a href="https://drewdevault.com/2020/11/01/What-is-Gemini-anyway.html">Drew DeVault</a>. Drew argues that:</p>
<blockquote>
<p>My disdain for web browsers is well documented. Web browsers are extraordinarily complex, and any attempt to build a new one would be a Sisyphean task. Successfully completing that implementation, if even possible, would necessarily produce a Lovecraftian mess: unmaintainable, full of security vulnerabilities, with gigabytes in RAM use and hours in compile times. And given that all of the contemporary web browsers that implement a sufficiently useful subset of web standards are ass and getting assier, what should we do?</p>
</blockquote>
<p>Fine, but the beloved plain duo of HTML + CSS still works just fine. There&rsquo;s no need to create a new, difficult-to-use protocol to <em>force</em> people to keep things simple. Unless you just wanna have fun and treat it like a toy or learning project; then go for it. Nothing wrong with that.</p>
<p>My interest for Gemini ends as soon as this post is published. Q.E.D.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p><a href="https://repology.org/project/amfora/versions">Packaged</a> for every relevant platform out there nowadays.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>]]></content:encoded></item><item><title>Google and Duckduckgo</title><link>https://www.perrotta.dev/2022/02/google-and-duckduckgo/</link><pubDate>Wed, 02 Feb 2022 18:51:00 -0500</pubDate><guid>https://www.perrotta.dev/2022/02/google-and-duckduckgo/</guid><description>&lt;p>My search engine of choice is &lt;a href="https://google.com/">Google&lt;/a>, nonetheless I still enjoy &lt;a href="https://duckduckgo.com/">DuckDuckGo&lt;/a> occasionally.&lt;/p>
&lt;p>The main reason to stick with Google is its superior quality, by the means of better search results. 20 years later, it&amp;rsquo;s still arguably the best search engine. Of course, part of the reason for that is contingent upon how much data it collects, but that&amp;rsquo;s a topic for another day&amp;hellip;&lt;/p>
&lt;p>There are at least three reasons to use DuckDuckGo as an &lt;em>alternative&lt;/em>:&lt;/p>
&lt;ul>
&lt;li>it&amp;rsquo;s privacy-focused, there&amp;rsquo;s no tracking and no bubbling&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>&lt;/li>
&lt;li>its search results stem from sources other than Google; these days, mostly from Bing&lt;/li>
&lt;li>it has &lt;a href="https://duckduckgo.com/bang">&lt;strong>!bangs&lt;/strong>&lt;/a>, lots of them&lt;/li>
&lt;/ul>
&lt;p>The quest(ion) then becomes: How can I use mostly Google, but still have quick access to DuckDuckGo bangs?&lt;/p></description><content:encoded><![CDATA[<p>My search engine of choice is <a href="https://google.com/">Google</a>, nonetheless I still enjoy <a href="https://duckduckgo.com/">DuckDuckGo</a> occasionally.</p>
<p>The main reason to stick with Google is its superior quality, by the means of better search results. 20 years later, it&rsquo;s still arguably the best search engine. Of course, part of the reason for that is contingent upon how much data it collects, but that&rsquo;s a topic for another day&hellip;</p>
<p>There are at least three reasons to use DuckDuckGo as an <em>alternative</em>:</p>
<ul>
<li>it&rsquo;s privacy-focused, there&rsquo;s no tracking and no bubbling<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></li>
<li>its search results stem from sources other than Google; these days, mostly from Bing</li>
<li>it has <a href="https://duckduckgo.com/bang"><strong>!bangs</strong></a>, lots of them</li>
</ul>
<p>The quest(ion) then becomes: How can I use mostly Google, but still have quick access to DuckDuckGo bangs?</p>
<p>There are several ways to do so.</p>
<h2 id="duckduckgoog">DuckDuckGoog</h2>
<p><a href="https://www.duckduckgoog.com/">DuckDuckGoog</a> is a search engine which does exactly that:</p>
<blockquote>
<p>Searches Google and !bangs DuckDuckGo. Tell your browser!</p>
</blockquote>
<ul>
<li>If I search for <code>i3</code>, it will open <a href="https://www.google.com/search?q=i3">https://www.google.com/search?q=i3</a> and probably think I am interested in Intel i3 CPUs.</li>
<li>If I search for <code>!aw i3</code>, using the ArchWiki bang, it opens <a href="https://wiki.archlinux.org/title/I3">https://wiki.archlinux.org/title/I3</a> and goes straight to the <code>i3</code> window manager page in the ArchWiki, exactly what I wanted.</li>
<li>If I search for <code>!ddg i3</code>, it opens <a href="https://duckduckgo.com/?q=i3">https://duckduckgo.com/?q=i3</a>, on DuckDuckGo.</li>
</ul>
<p>Caveat: You cannot add custom search engines to Safari, therefore this method only works in other browsers (Firefox, Chrome, etc).</p>
<h3 id="self-hosted">Self-Hosted</h3>
<p>DuckDuckGoog <a href="https://www.duckduckgoog.com/privacy">claims</a> to collect no data:</p>
<blockquote>
<p>It&rsquo;s quite simple. DuckDuckGoog doesn&rsquo;t track any queries submitted whatsoever, It simply redirects you to DuckDuckGo or Google depending on whether your search contains a !bang or not.</p>
</blockquote>
<p>If you still don&rsquo;t trust it for some reason, you could also self-host it in your own server, as it&rsquo;s <a href="https://github.com/mikecrittenden/duckduckgoog">open source</a>.</p>
<p>One advantage of doing so is using (and owning) your own infrastructure, which is probably more reliable in terms of bandwidth and latency than a random guy&rsquo;s server in the wild.</p>
<h2 id="bang-quick-search">!Bang Quick Search</h2>
<p><a href="https://chrome.google.com/webstore/detail/bang-quick-search/kcopjlobikiakoacoadbnghpdcmngali">!Bang Quick Search</a> is a Chrome extension:</p>
<blockquote>
<p>This extension adds DuckDuckGo !bang search to chrome. You can use it from the URL bar as long as your default search engine is either google or bing (for now). You can also use it directly on google&rsquo;s and bing&rsquo;s websites.</p>
</blockquote>
<p>So long as your search engine is set to either Google or Bing, it will intercept <code>!bangs</code> from your query to redirect them to DuckDuckGo.</p>
<p>Tip: Use <code>!ddg</code> to search on DuckDuckGo.</p>
<p>Caveat: As a Chrome extension, it obviously only works in Chrome (or any of its derivatives like Edge or Vivaldi).</p>
<h2 id="duckduckgo">DuckDuckGo</h2>
<p>Another simple way is to just use DuckDuckGo directly. Whenever you want to go to Google, just add <code>!g</code> to your query.</p>
<h2 id="final-words">Final words</h2>
<p>I used all three methods in the past. My favorite one these days is the Chrome Extension because Chrome is my current browser.</p>
<p>As a fallback I find that using DuckDuckGo directly is acceptable as well, however it quickly becomes quite annoying to constantly add <code>!g</code> to every query. Defaults matter.</p>
<h2 id="related">Related</h2>
<ul>
<li><a href="https://blog.meain.io/2019/switching-to-duckduckgo/">Switching to DuckDuckGo</a></li>
</ul>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Biased search results based on your past searches.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>]]></content:encoded></item><item><title>Pihole: Add custom DNS mappings</title><link>https://www.perrotta.dev/2022/01/pihole-add-custom-dns-mappings/</link><pubDate>Tue, 25 Jan 2022 21:50:53 -0500</pubDate><guid>https://www.perrotta.dev/2022/01/pihole-add-custom-dns-mappings/</guid><description>&lt;p>This post covers how to add DNS entries / mappings to a local network managed
with &lt;a href="https://pi-hole.net/">pihole&lt;/a>.&lt;/p></description><content:encoded><![CDATA[<p>This post covers how to add DNS entries / mappings to a local network managed
with <a href="https://pi-hole.net/">pihole</a>.</p>
<p>There are several ways to do so:</p>
<h2 id="1-the-cli-way-etcpihole">1. The CLI way: <code>/etc/pihole/</code></h2>
<p>Edit <code>/etc/pihole/custom.list</code>, set one mapping per line, just as you would for
<code>/etc/hosts</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>$ cat /etc/pihole/custom.list
</span></span><span style="display:flex;"><span>127.0.0.1     localhost.corp.google.com
</span></span><span style="display:flex;"><span>192.168.1.75  myhostname.home.arpa
</span></span></code></pre></div><p>This works because <code>/etc/dnsmasq.d/01-pihole.conf</code> contains
<code>addn-hosts=/etc/pihole/custom.list</code> by default.</p>
<p>From <a href="https://wiki.gentoo.org/wiki/Dnsmasq#Additional_hosts_file">Gentoo Wiki</a>:</p>
<blockquote>
<p>It is possible to refer to an (additional) hosts file to use as source for
DNS queries. To do so, add the -H /path/to/hostsfile
(&ndash;addn-hosts=/path/to/hostsfile) command line option. It is also possible to
pass a directory; in that case, all files inside that directory will be
treated as additional hosts files.</p>
</blockquote>
<h2 id="2-the-cli-way-etcdnsmasqd">2. The CLI way: <code>/etc/dnsmasq.d/</code></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>$ cat /etc/dnsmasq.d/03-pihole-custom-dns.conf
</span></span><span style="display:flex;"><span>address<span style="color:#f92672">=</span>/localhost.corp.google.com/127.0.0.1
</span></span><span style="display:flex;"><span>address<span style="color:#f92672">=</span>/myhostname.home.arpa/192.168.1.75
</span></span></code></pre></div><p>From <a href="https://wiki.archlinux.org/title/Dnsmasq#Override_addresses">ArchWiki</a>:</p>
<blockquote>
<p>In some cases, such as when operating a captive portal, it can be useful
to resolve specific domains names to a hard-coded set of addresses.
This is done with the address config.</p>
</blockquote>
<h2 id="3-the-web-way">3. The Web way</h2>
<p>Navigate to <a href="http://pi.hole/admin/dns_records.php">http://pi.hole/admin/dns_records.php</a> and set your DNS records
there. From pihole docs:</p>
<blockquote>
<p>The order of locally defined DNS records is:</p>
<ol>
<li>The device&rsquo;s host name (<code>/etc/hostname</code>) and <code>pi.hole</code></li>
<li>Configured in a config file in <code>/etc/dnsmasq.d/</code></li>
<li>Read from <code>/etc/hosts</code></li>
<li>Read from the &ldquo;Local (custom) DNS&rdquo; list (stored in <code>/etc/pihole/custom.list</code>) (the aforementioned ways)</li>
</ol>
<p>Only the first record will trigger an address-to-name association.</p>
</blockquote>
<h2 id="wrapping-up">Wrapping up</h2>
<p>Then restart pihole to apply changes:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>$ pihole restartdns
</span></span></code></pre></div>]]></content:encoded></item><item><title>Introspect the local network for Pihole</title><link>https://www.perrotta.dev/2022/01/introspect-the-local-network-for-pihole/</link><pubDate>Sun, 23 Jan 2022 13:34:58 -0500</pubDate><guid>https://www.perrotta.dev/2022/01/introspect-the-local-network-for-pihole/</guid><description>&lt;p>Recently I needed to figure out what the IP address of my &lt;a href="https://pi-hole.net/">pihole&lt;/a>
instance was in my &lt;a href="https://www.raspberrypi.org/">Raspberry Pi&lt;/a> in my local network.&lt;/p></description><content:encoded><![CDATA[<p>Recently I needed to figure out what the IP address of my <a href="https://pi-hole.net/">pihole</a>
instance was in my <a href="https://www.raspberrypi.org/">Raspberry Pi</a> in my local network.</p>
<h2 id="finding-the-raspberry-pi">Finding the Raspberry Pi</h2>
<h3 id="nmap">nmap</h3>
<p><a href="https://nmap.org/"><code>nmap</code></a> to the rescue!</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#75715e"># nmap -sS 192.168.1.1-255 | tee network.txt | less</span>
</span></span></code></pre></div><p>The relevant snippets to the pihole look like this:</p>
<pre tabindex="0"><code class="language-none" data-lang="none">Nmap scan report for pi.hole (192.168.1.XX)
Host is up (0.0052s latency).
Not shown: 997 closed tcp ports (reset)
PORT   STATE SERVICE
22/tcp open  ssh
53/tcp open  domain
80/tcp open  http
MAC Address: AA:AA:AA:AA:AA:AA (Raspberry Pi Foundation)

Nmap scan report for pi.hole (192.168.1.YY)
Host is up (0.0059s latency).
Not shown: 997 closed tcp ports (reset)
PORT   STATE SERVICE
22/tcp open  ssh
53/tcp open  domain
80/tcp open  http
MAC Address: BB:BB:BB:BB:BB:BB (Raspberry Pi Foundation)
</code></pre><p>There are two IP addresses, one for the ethernet interface (<code>eth0</code>) and the
other for the wifi (<code>wlan0</code>). Later on I would disable the wifi interface.</p>
<p>The 3 open ports are for services you would expect in a pihole:</p>
<ul>
<li><code>ssh</code> (port 22) for remote access / debugging / troubleshooting</li>
<li>DNS server (port 53) for the <code>dnsmasq</code> server that pihole uses underneath for adblocking</li>
<li>HTTP server (port 80) for the <a href="http://pi.hole/admin">http://pi.hole/admin</a> web management UI</li>
</ul>
<h3 id="ip">ip</h3>
<p>Another way is to use the <code>ip</code> command. In particular, <code>ip neigh</code> lists the
neighbours, one of which should be the pihole.</p>
<h2 id="testing-the-pihole">Testing the pihole</h2>
<p>One effective way to test the pihole is to see if <code>analytics.google.com</code> is
blocked. There are several ways to do so:</p>
<ol>
<li><code>ping</code> should return a local address like <code>127.0.0.1</code> or <code>0.0.0.0</code>.</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>$ ping analytics.google.com
</span></span><span style="display:flex;"><span>PING analytics.google.com <span style="color:#f92672">(</span>127.0.0.1<span style="color:#f92672">)</span> 56<span style="color:#f92672">(</span>84<span style="color:#f92672">)</span> bytes of data.
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">64</span> bytes from localhost <span style="color:#f92672">(</span>127.0.0.1<span style="color:#f92672">)</span>: icmp_seq<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span> ttl<span style="color:#f92672">=</span><span style="color:#ae81ff">64</span> time<span style="color:#f92672">=</span>0.023 ms
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">64</span> bytes from localhost <span style="color:#f92672">(</span>127.0.0.1<span style="color:#f92672">)</span>: icmp_seq<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span> ttl<span style="color:#f92672">=</span><span style="color:#ae81ff">64</span> time<span style="color:#f92672">=</span>0.031 ms
</span></span><span style="display:flex;"><span>^C
</span></span><span style="display:flex;"><span>--- analytics.google.com ping statistics ---
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">2</span> packets transmitted, <span style="color:#ae81ff">2</span> received, 0% packet loss, time 1002ms
</span></span><span style="display:flex;"><span>rtt min/avg/max/mdev <span style="color:#f92672">=</span> 0.023/0.027/0.031/0.004 ms
</span></span></code></pre></div><ol start="2">
<li>Ditto for a DNS lookup utility such as <code>dig</code>:</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>$ dig +short analytics.google.com
</span></span><span style="display:flex;"><span>0.0.0.0
</span></span></code></pre></div><p>Other ways: <code>drill</code>, <code>host</code>, <code>nslookup</code>, <code>systemd-resolve</code>.</p>
<p><a href="https://d3ward.github.io/toolz/adblock.html">https://d3ward.github.io/toolz/adblock.html</a> seems to be a reasonable website to
test whether your adblock blocklists are properly working. Alternatively, just
visit any modern and large news corporation website, it will probably be full
of ads.</p>
<h2 id="troubleshooting-the-pihole">Troubleshooting the pihole</h2>
<p>If DNS resolution fails from the pihole itself, run <code>pihole restartdns</code>. Then
<code>ping google.com</code>. The ping should work, if it doesn&rsquo;t then there&rsquo;s a bigger
problem, out of scope of this post. If the ping works now but stops working
later on once you eventually reboot the Pi, consider triggering this command at
startup via <code>cron</code> or a systemd timer.</p>
<p>If DNS resolution works from the pihole but fails from a neighbouring device,
double-check if the device is properly configured: its DNS should be set to the
IP address of the pihole. Check these:</p>
<ul>
<li><code>/etc/resolv.conf</code></li>
<li>If the system uses <code>systemd-resolved</code>, run <code>resolvectl</code>.</li>
</ul>
<p>Another possibility is that the pihole might be configured to only answer
queries from <code>eth0</code>. Use the <a href="http://pi.hole/admin">http://pi.hole/admin</a> interface to ensure the
pihole is configured to answer DNS queries from the local network.</p>
<h2 id="setting-a-static-ip-in-the-pihole">Setting a static IP in the pihole</h2>
<p>There are several ways to do so, in order of recommendation:</p>
<ul>
<li>
<p>Static DHCP lease from your router. If running a modem, this will likely not
work. Prefer running a DHCP server from the pihole.</p>
</li>
<li>
<p><code>dhcpcd</code>: This is typically done as part of the standard pihole setup.</p>
</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>$ cat /etc/dhcpcd.conf
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span><span style="color:#75715e"># fallback to static profile on eth0</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#interface eth0</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#fallback static_eth0</span>
</span></span><span style="display:flex;"><span>interface eth0
</span></span><span style="display:flex;"><span>        static ip_address<span style="color:#f92672">=</span>192.168.1.XX/24
</span></span><span style="display:flex;"><span>        static routers<span style="color:#f92672">=</span>192.168.1.1
</span></span><span style="display:flex;"><span>        static domain_name_servers<span style="color:#f92672">=</span>
</span></span></code></pre></div><p>Note: Restart <code>dhcpcd</code> to apply: <code>systemctl restart dhcpcd</code>.</p>
<ul>
<li><code>/etc/network/interfaces</code> if running Raspberry Pi OS (debian):</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>$ sudoedit /etc/network/interfaces.d/pihole
</span></span><span style="display:flex;"><span>auto lo
</span></span><span style="display:flex;"><span>iface lo inet loopback
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>auto eth0
</span></span><span style="display:flex;"><span>iface eth0 inet static
</span></span><span style="display:flex;"><span>    address 192.168.1.XX
</span></span><span style="display:flex;"><span>    netmask 255.255.255.0
</span></span><span style="display:flex;"><span>    gateway 192.168.1.1
</span></span></code></pre></div><p>Note: Reconfigure debian networking to apply: <code>systemctl restart networking</code>.</p>
<ul>
<li>Static DHCP lease from the pihole itself if it&rsquo;s running a DHCP server. This
solution is a bit redundant and should only be applied as last resort.</li>
</ul>]]></content:encoded></item><item><title>Debian: Enable unattended upgrades</title><link>https://www.perrotta.dev/2022/01/debian-enable-unattended-upgrades/</link><pubDate>Sun, 16 Jan 2022 02:07:00 -0500</pubDate><guid>https://www.perrotta.dev/2022/01/debian-enable-unattended-upgrades/</guid><description>&lt;p>Here&amp;rsquo;s how we can enable automatic (unattended) package upgrades in Debian.&lt;/p></description><content:encoded><![CDATA[<p>Here&rsquo;s how we can enable automatic (unattended) package upgrades in Debian.</p>
<h2 id="howto">Howto</h2>
<p>Install the <code>unattended-upgrades</code> package with <code>apt(8)</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>% apt install unattended-upgrades
</span></span></code></pre></div><p>The service is then enabled and started automatically:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>$ systemctl status unattended-upgrades
</span></span><span style="display:flex;"><span>● unattended-upgrades.service - Unattended Upgrades Shutdown
</span></span><span style="display:flex;"><span>     Loaded: loaded <span style="color:#f92672">(</span>/lib/systemd/system/unattended-upgrades.service; enabled; vendor preset: enabled<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>     Active: active <span style="color:#f92672">(</span>running<span style="color:#f92672">)</span> since Sun 2022-01-16 02:05:42 EST; 35s ago
</span></span><span style="display:flex;"><span>       Docs: man:unattended-upgrade<span style="color:#f92672">(</span>8<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>   Main PID: <span style="color:#ae81ff">22442</span> <span style="color:#f92672">(</span>unattended-upgr<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>      Tasks: <span style="color:#ae81ff">2</span> <span style="color:#f92672">(</span>limit: 1597<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>        CPU: 516ms
</span></span><span style="display:flex;"><span>     CGroup: /system.slice/unattended-upgrades.serviceGk
</span></span><span style="display:flex;"><span>             └─22442 /usr/bin/python3 /usr/share/unattended-upgrades/unattended-upgrade-shutdown --wait-for-signal
</span></span></code></pre></div><p>By default, only security updates are enabled. We can enable all updates by uncommenting the applicable lines:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>$ sudoedit /etc/apt/apt.conf.d/50unattended-upgrades
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>Unattended-Upgrade::Origins-Pattern <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>        // Codename based matching:
</span></span><span style="display:flex;"><span>        // This will follow the migration of a release through different
</span></span><span style="display:flex;"><span>        // archives <span style="color:#f92672">(</span>e.g. from testing to stable and later oldstable<span style="color:#f92672">)</span>.
</span></span><span style="display:flex;"><span>        // Software will be the latest available <span style="color:#66d9ef">for</span> the named release,
</span></span><span style="display:flex;"><span>        // but the Debian release itself will not be automatically upgraded.
</span></span><span style="display:flex;"><span>        // <span style="color:#e6db74">&#34;origin=Debian,codename=</span><span style="color:#e6db74">${</span>distro_codename<span style="color:#e6db74">}</span><span style="color:#e6db74">-updates&#34;</span>;
</span></span><span style="display:flex;"><span>        // <span style="color:#e6db74">&#34;origin=Debian,codename=</span><span style="color:#e6db74">${</span>distro_codename<span style="color:#e6db74">}</span><span style="color:#e6db74">-proposed-updates&#34;</span>;
</span></span><span style="display:flex;"><span>        // <span style="color:#e6db74">&#34;origin=Debian,codename=</span><span style="color:#e6db74">${</span>distro_codename<span style="color:#e6db74">}</span><span style="color:#e6db74">,label=Debian&#34;</span>;
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;origin=Debian,codename=</span><span style="color:#e6db74">${</span>distro_codename<span style="color:#e6db74">}</span><span style="color:#e6db74">,label=Debian-Security&#34;</span>;
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;origin=Debian,codename=</span><span style="color:#e6db74">${</span>distro_codename<span style="color:#e6db74">}</span><span style="color:#e6db74">-security,label=Debian-Security&#34;</span>;
</span></span><span style="display:flex;"><span>...
</span></span></code></pre></div><p>For debugging, one should run:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>$ sudo unattended-upgrade -d
</span></span></code></pre></div><p>We could go beyond and add logging by the means of <code>etckeeper</code>, just like how we did for Alpine Linux&rsquo;s <a href="https://www.perrotta.dev/2022/01/alpine-linux-apk-logs-with-etckeeper/"><code>apk</code></a></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>% apt install etckeeper
</span></span><span style="display:flex;"><span>Reading package lists... Done
</span></span><span style="display:flex;"><span>Building dependency tree... Done
</span></span><span style="display:flex;"><span>Reading state information... Done
</span></span><span style="display:flex;"><span>The following NEW packages will be installed:
</span></span><span style="display:flex;"><span>  etckeeper
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">0</span> upgraded, <span style="color:#ae81ff">1</span> newly installed, <span style="color:#ae81ff">0</span> to remove and <span style="color:#ae81ff">0</span> not upgraded.
</span></span><span style="display:flex;"><span>Need to get 54.4 kB of archives.
</span></span><span style="display:flex;"><span>After this operation, <span style="color:#ae81ff">180</span> kB of additional disk space will be used.
</span></span><span style="display:flex;"><span>Get:1 http://raspbian.freemirror.org/raspbian bullseye/main armhf etckeeper all 1.18.16-1 <span style="color:#f92672">[</span>54.4 kB<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>Fetched 54.4 kB in 1s <span style="color:#f92672">(</span>84.3 kB/s<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>Preconfiguring packages ...
</span></span><span style="display:flex;"><span>Selecting previously unselected package etckeeper.
</span></span><span style="display:flex;"><span><span style="color:#f92672">(</span>Reading database ... <span style="color:#ae81ff">44403</span> files and directories currently installed.<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>Preparing to unpack .../etckeeper_1.18.16-1_all.deb ...
</span></span><span style="display:flex;"><span>Unpacking etckeeper <span style="color:#f92672">(</span>1.18.16-1<span style="color:#f92672">)</span> ...
</span></span><span style="display:flex;"><span>Setting up etckeeper <span style="color:#f92672">(</span>1.18.16-1<span style="color:#f92672">)</span> ...
</span></span><span style="display:flex;"><span>Created symlink /etc/systemd/system/multi-user.target.wants/etckeeper.timer → /lib/systemd/system/etckeeper.timer.
</span></span><span style="display:flex;"><span>etckeeper.service is a disabled or a static unit, not starting it.
</span></span><span style="display:flex;"><span>...
</span></span></code></pre></div><p><code>etckeeper</code> is enabled and works out-of-the-box as well:</p>
<pre tabindex="0"><code>systemctl status etckeeper.timer
● etckeeper.timer - Daily autocommit of changes in /etc directory
     Loaded: loaded (/lib/systemd/system/etckeeper.timer; enabled; vendor preset: enabled)
     Active: active (waiting) since Sun 2022-01-16 02:28:44 EST; 2min 36s ago
    Trigger: Mon 2022-01-17 02:28:44 EST; 23h left
   Triggers: ● etckeeper.service
       Docs: man:etckeeper(8)
</code></pre><p>Here&rsquo;s what a typical log looks like:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>$ <span style="color:#f92672">(</span>cd /etc/etckeeper <span style="color:#f92672">&amp;&amp;</span> sudo git log<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>commit 8f9f5e31d9abb833cf645825c1cbda15336818b7 <span style="color:#f92672">(</span>HEAD -&gt; master<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>Author: root &lt;root@raspberry&gt;
</span></span><span style="display:flex;"><span>Date:   Sun Jan <span style="color:#ae81ff">16</span> 06:25:28 <span style="color:#ae81ff">2022</span> -0500
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    daily autocommit
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>commit 5a6478711a1a1198535d5062ca309afb5c99c0eb
</span></span><span style="display:flex;"><span>Author: root &lt;root@raspberry&gt;
</span></span><span style="display:flex;"><span>Date:   Sun Jan <span style="color:#ae81ff">16</span> 02:29:01 <span style="color:#ae81ff">2022</span> -0500
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    Initial commit
</span></span></code></pre></div><h2 id="references">References</h2>
<ul>
<li><a href="https://wiki.debian.org/UnattendedUpgrades">https://wiki.debian.org/UnattendedUpgrades</a></li>
</ul>]]></content:encoded></item><item><title>★ Alpine Linux on Raspberry Pi: Diskless Mode with persistent storage</title><link>https://www.perrotta.dev/2022/01/alpine-linux-on-raspberry-pi-diskless-mode-with-persistent-storage/</link><pubDate>Sat, 15 Jan 2022 23:18:56 -0500</pubDate><guid>https://www.perrotta.dev/2022/01/alpine-linux-on-raspberry-pi-diskless-mode-with-persistent-storage/</guid><description>&lt;p>Use case: Given an Alpine Linux &lt;strong>diskless&lt;/strong>&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup> installation meant for
a Raspberry Pi setup, we would like to add a persistent storage component to it
to make it survive across reboots.&lt;/p></description><content:encoded><![CDATA[<p>Use case: Given an Alpine Linux <strong>diskless</strong><sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> installation meant for
a Raspberry Pi setup, we would like to add a persistent storage component to it
to make it survive across reboots.</p>
<h2 id="goal">Goal</h2>
<p>The <a href="https://wiki.alpinelinux.org/wiki/Installation">Alpine Linux Wiki</a> covers most of the installation process, hence I will only document the bits that were lacking and/or confusing therein.</p>
<p>My use case is the following:</p>
<blockquote>
<p>Given a Raspberry Pi 3B with an old 4GiB SD Card as CF storage<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>, install Alpine Linux in diskless mode. Find a way to preserve modifications in <code>/etc</code> and <code>/var</code>, as well as any installed packages through its <code>apk</code> package manager.</p>
</blockquote>
<p>Let&rsquo;s follow the steps outlined in the wiki.</p>
<h2 id="copy-alpine-to-the-sd-card">Copy Alpine to the SD Card</h2>
<blockquote>
<p>Grab the SD card and install Alpine Linux in it.</p>
</blockquote>
<p>Alpine provides officially supported images designed for the Raspberry Pi.</p>
<p>Most Linux distributions provide an <code>.iso</code> or <code>.img</code> file to be installed with a tool like <a href="https://www.balena.io/etcher/">Balena Etcher</a>, <a href="https://rufus.ie/en/">Rufus</a>, <a href="https://www.raspberrypi.com/news/raspberry-pi-imager-imaging-utility/"><strong>Raspberry Pi Imager</strong></a> or plain <code>dd</code><sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>.</p>
<p>Alpine is not like most Linux distributions: Instead, it provides a <code>.tar.gz</code> archive with files that should be copied directly to the SD card. Grab the latest version (3.15 at the time of this post) from <a href="https://alpinelinux.org/downloads/">https://alpinelinux.org/downloads/</a>. There are 3 options:</p>
<ul>
<li>
<p><code>armhf</code>: Works with all Pis, but may perform less optimally on recent versions.</p>
</li>
<li>
<p><code>armv7</code>: Works with the Pi 3B, 32-bit.</p>
</li>
<li>
<p><code>aarch64</code>: Works with the Pi 3B, 64-bit.</p>
</li>
</ul>
<p>I opted for <code>aarch64</code> to make it 64-bit, but <code>armv7</code> would also have worked well for my setup. In fact, Raspberry Pi OS (Debian) uses <code>armv7</code> (32-bit) at the time of this writing.</p>
<p>Before copying files over, format the SD Card. As I was doing this
from a Windows machine because it was the only one I had readily available with
a SD card slot, I just used the native Windows Disk Management tool to do so.
I decided to allocate a 100MB<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> FAT32 partition. The rest of the SD card would be
blank for now. Alpine is surprisingly small, 100MB was more than enough for the kernel and other needed files.</p>
<p>Once the SD card is formatted, copy the files over to it. It turns out Windows cannot extract tarballs (<code>.tar.gz</code>); a tool like <a href="https://www.7-zip.org/">7-zip</a> should do the job. Copy the files over to the root of the newly allocated FAT32 partition, and then safely eject the SD card.</p>
<h2 id="boot-alpine-from-the-sd-card">Boot Alpine from the SD Card</h2>
<p>The next step is to insert the SD Card into the Pi and then boot. I had some trouble in this step and eventually figured out I didn&rsquo;t mark the primary FAT32 partition as bootable. Unfortunately it&rsquo;s not straightforward to mark the partition as bootable from Windows. On a Linux machine there&rsquo;s a wide array of tools to do so: <code>fdisk</code>, <code>cfdisk</code> (TUI), <code>sfdisk</code> (scriptable <code>fdisk</code>), <code>parted</code>, <code>gparted</code> (GUI) are some of them. I worked around that by installing Raspberry Pi OS on the SD card with the Raspberry Pi imager, and then overwriting it with the Alpine files. This works because the Raspberry PI OS installation marks the FAT32 partition as bootable.</p>
<h2 id="install-alpine">Install Alpine</h2>
<p>Installing Alpine is well documented in the <a href="https://wiki.alpinelinux.org/wiki/Installation">wiki</a> thus it won&rsquo;t be covered here. It basically comes down to invoking <code>setup-alpine</code>, which then invokes other <code>setup-*</code> scripts.</p>
<p>Keep in mind we&rsquo;re not really &ldquo;installing&rdquo; Alpine as this is a diskless installation. A more accurate term here would be &ldquo;configuring&rdquo;.</p>
<p>Before invoking the installation script, I created a second primary partition in the SD card, set to <code>ext4</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#75715e"># Configure networking to get working internet access.</span>
</span></span><span style="display:flex;"><span>% setup-interfaces
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Install some partitioning tools.</span>
</span></span><span style="display:flex;"><span>% apk add cfdisk e2fsprogs
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Create a second partition (mmcblk0p2) and write it.</span>
</span></span><span style="display:flex;"><span>% cfdisk /dev/mmcblk0
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Format the partition as ext4.</span>
</span></span><span style="display:flex;"><span>% mkfs.ext4 /dev/mmcblk0p2
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Mount the partition under /media.</span>
</span></span><span style="display:flex;"><span>% mount /dev/mmcblk0p2 /media/mmcblk0p2
</span></span></code></pre></div><p>The installation is straightforward, we just need to pay attention to a few select steps:</p>
<ul>
<li><code>setup-disk</code>: Select <code>none</code> to ensure a <code>diskless</code> installation<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>.</li>
<li><code>setup-apkcache</code>: Select <code>/media/mmcblk0p2/cache</code> to persist downloaded <code>apk</code> packages.</li>
<li><code>setup-lbu</code>: Edit <code>/etc/lbu/lbu.conf</code> and set <code>LBU_MEDIA=&quot;mmcblk0p2&quot;</code>. Note: Do not add <code>/media</code> as it is implicit.</li>
</ul>
<p>Once the installation is complete, run <code>lbu commit</code> to persist the changes in the second partition. Once you do so, a <code>&lt;hostname&gt;.apkovl.tar.gz</code><sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> file should materialize on <code>/media/mmcblk0p2/</code>.</p>
<p>This is a good moment to reboot. Before we do so, let&rsquo;s cache the packages we had previously downloaded.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#75715e"># Cache packages.</span>
</span></span><span style="display:flex;"><span>% apk cache download
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>% reboot
</span></span></code></pre></div><h2 id="after-the-first-reboot">After the first reboot</h2>
<p>If everything worked as expected, once you reboot all your previously installed packages should have been preserved and automatically restored / reinstalled, as well as your modifications done to <code>/etc</code>.</p>
<p>From this point on, whenever you install a new package that you want to be preserved for subsequent reboots, run <code>lbu commit</code> afterwards. For example:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>% apk add vim
</span></span><span style="display:flex;"><span>% lbu commit
</span></span></code></pre></div><p>If you would like to see what is going to be committed, run <code>lbu status</code> or <code>lbu diff</code> before doing the actual commit. Whenever you commit, <code>/media/mmcblk0p2/&lt;hostname&gt;.apkovl.tar.gz</code> gets overwritten with your most recent modifications.</p>
<p>It&rsquo;s possible to keep more than one backup file by changing <code>BACKUP_LIMIT=</code> in <code>/etc/lbu/lbu.conf</code>. This is specially handy if you decide to revert to an earlier system snapshot / state later on. The stock config looks like this:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>% cat /etc/lbu/lbu.conf
</span></span><span style="display:flex;"><span><span style="color:#75715e"># what cipher to use with -e option</span>
</span></span><span style="display:flex;"><span>DEFAULT_CIPHER<span style="color:#f92672">=</span>aes-256-cbc
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Uncomment the row below to encrypt config by default</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># ENCRYPTION=$DEFAULT_CIPHER</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Uncomment below to avoid &lt;media&gt; option to &#39;lbu commit&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Can also be set to &#39;floppy&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># LBU_MEDIA=usb</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Set the LBU_BACKUPDIR variable in case you prefer to save the apkovls</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># in a normal directory instead of mounting an external media.</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># LBU_BACKUPDIR=/root/config-backups</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Uncomment below to let lbu make up to 3 backups</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># BACKUP_LIMIT=3</span>
</span></span></code></pre></div><p><strong>Tip</strong>: You can find the list of all explicitly installed packages in <code>/etc/apk/world</code>.</p>
<h2 id="the-last-piece-make-var-persistent">The last piece: make /var persistent</h2>
<p>There are three natural ways that come to mind to make <code>/var</code> persistent:</p>
<h3 id="a-separate-partition-or-file">A) Separate partition (or file)</h3>
<p>Instead of two partitions (FAT32 and ext4), create 3 partitions: FAT32, ext4 and ext4. Use the latter one to mount <code>/var</code> on, saving this information in <code>/etc/fstab</code>. The main disadvantage of this setup is that you&rsquo;ll need to allocate a fixed amount of space of each of the ext4 partitions and it may be difficult to figure out how to split the space between them.</p>
<p>A variant of this approach is to just create the third partition as a file:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#75715e"># 500MB file</span>
</span></span><span style="display:flex;"><span>% dd <span style="color:#66d9ef">if</span><span style="color:#f92672">=</span>/dev/zero of<span style="color:#f92672">=</span>/media/mmcblk0p2/var.img bs<span style="color:#f92672">=</span>1M count<span style="color:#f92672">=</span><span style="color:#ae81ff">500</span> status<span style="color:#f92672">=</span>progress
</span></span><span style="display:flex;"><span>% mkfs.ext4 /media/mmcblk0p2/var.img
</span></span><span style="display:flex;"><span>% mount /media/mmcblk0p2/var.img /var
</span></span></code></pre></div><p>This works because the Linux kernel supports mounting files as if they were device blocks, treating them as loop devices (pseudo-devices).</p>
<p>I don&rsquo;t like these approaches because they shadow the preexisting <code>/var</code> from the boot media, which in turn messes up with existing services that use it such as <code>cron</code>: <code>% crontab -l</code> would fail. One workaround would be to mount a <code>/var</code> subdirectory instead: for example, <code>/var/lib/docker</code> for docker.</p>
<h3 id="b-bind-mount">B) Bind mount</h3>
<p>This one is straightforward:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>% mount --bind /media/mmcblk0p2/var/lib/docker /var/lib/docker
</span></span></code></pre></div><p>The actual partition lives in the SD card, however we make a bind mount under
<code>/var</code>, which is like an <em>alias</em>. From <a href="https://unix.stackexchange.com/questions/198590/what-is-a-bind-mount">Stack Exchange</a>:</p>
<blockquote>
<p>A bind mount is an alternate view of a directory tree. Classically, mounting creates a view of a storage device as a directory tree. A bind mount instead takes an existing directory tree and replicates it under a different point. The directories and files in the bind mount are the same as the original. Any modification on one side is immediately reflected on the other side, since the two views show the same data.</p>
</blockquote>
<h3 id="c-overlay-mount">C) Overlay mount</h3>
<p>From <a href="https://wiki.archlinux.org/title/Overlay_filesystem">ArchWiki</a>:</p>
<blockquote>
<p>Overlayfs allows one, usually read-write, directory tree to be overlaid onto another, read-only directory tree. All modifications go to the upper, writable layer. This type of mechanism is most often used for live CDs but there is a wide variety of other uses.</p>
</blockquote>
<p>It&rsquo;s perfect for our use case, which uses a live bootable SD card for Alpine. It blends the preexisting, ephemeral, in-memory <code>/var</code> with the persistent in-disk <code>/var</code>.</p>
<p>I wanted to mount <code>/var</code> directly but found it to be problematic for the same reasons mentioned earlier, therefore I just went with <code>/var/lib/docker</code> instead:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#75715e"># Create overlay upper and work directories.</span>
</span></span><span style="display:flex;"><span>% mkdir -p /media/mmcblk0p2/var/lib/docker /media/mmcblk0p2/var/lib/docker-work
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Add mountpoint entry to fstab. Note: The work dir must be an empty directory in the same filesystem mount as the upper directory.</span>
</span></span><span style="display:flex;"><span>% echo <span style="color:#e6db74">&#34;overlay /var/lib/docker overlay lowerdir=/var/lib/docker,upperdir=/media/mmcblk0p2/var/lib/docker,workdir=/media/mmcblk0p2/var/lib/docker-work 0 0&#34;</span> &gt;&gt; /etc/fstab
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Mount all fstab entries, including our newly added one.</span>
</span></span><span style="display:flex;"><span>% mount -a
</span></span></code></pre></div><h2 id="conclusion">Conclusion</h2>
<p>I opted for the third approach, using an overlay mount, it was the most
seamless one. A bind mount would have been fine as well.</p>
<p>The final setup works surprisingly well:</p>
<ul>
<li>Alpine Linux is very lightweight and runs mostly from RAM</li>
<li><code>apk</code> cache is persistent to the ext4 partition</li>
<li><code>/var/</code> is persistent to the ext4 partition</li>
<li><code>lbu commit</code> persists changes in <code>/etc/</code> and <code>/home/</code> in the ext4 partition</li>
<li>Every reboot fully resets the system sans persistent components above</li>
</ul>
<h2 id="references">References</h2>
<ul>
<li><a href="https://vincentserpoul.github.io/post/alpine-linux-rpi0/">https://vincentserpoul.github.io/post/alpine-linux-rpi0/</a></li>
<li><a href="http://dahl-jacobsen.dk/tips/blog/2021-04-08-docker-on-alpine-linux/">http://dahl-jacobsen.dk/tips/blog/2021-04-08-docker-on-alpine-linux/</a></li>
<li><a href="http://dahl-jacobsen.dk/tips/blog/2018-03-15-alpine-on-raspberry-pi/">http://dahl-jacobsen.dk/tips/blog/2018-03-15-alpine-on-raspberry-pi/</a></li>
</ul>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Running (almost) fully from RAM.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>CF = Compact disk.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>On Linux I&rsquo;d usually opt for <code>dd</code>, on Windows the Raspberry Pi Imager is a sensible choice.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>100MB is overly conservative, but keep in mind I had a very small SD Card, with only 4GiB storage. 250MB or even 500MB should be a more sensible default if you have a bigger SD Card (e.g. 32GiB).&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>An alternative is to select <code>data</code> disk mode, but it didn&rsquo;t work for me.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p><em>ovl</em> is short for <em>overlay</em>. Not to be confused with <em>vol</em> for <em>volume</em>.&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>]]></content:encoded></item><item><title>★ Miniflux: Rolling my own RSS Reader</title><link>https://www.perrotta.dev/2022/01/miniflux-rolling-my-own-rss-reader/</link><pubDate>Mon, 03 Jan 2022 17:56:56 -0500</pubDate><guid>https://www.perrotta.dev/2022/01/miniflux-rolling-my-own-rss-reader/</guid><description>&lt;p>This article describes my experience transitioning to, setting up and using the
&lt;a href="https://miniflux.app/">Miniflux&lt;/a> RSS reader for the first time.&lt;/p></description><content:encoded><![CDATA[<p>This article describes my experience transitioning to, setting up and using the
<a href="https://miniflux.app/">Miniflux</a> RSS reader for the first time.</p>
<h2 id="preamble">Preamble</h2>
<p>I always kind of enjoyed following people and blogs via RSS, even though it has never been a key part of my workflow (nor of the mainstream web). That said, I am not here to convince you why RSS is great, there are good existing resources<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup><sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> for that already.</p>
<p>Initially I had used Commafeed, Feedly and Inoreader, which are hosted solutions. They are mostly OK, especially if you only have a handful of feeds. Their free offerings are quite decent, with a limit of a hundred or so feeds. They also have mobile clients (Android, iOS) which are a must these days. I was never fully converted to them though, and my workflow therein would only last for a few weeks or months. Some common barriers were:</p>
<ul>
<li>
<p>their recommendations and &lsquo;machine learning&rsquo; fluff were a consistent source of stress, with a fear of missing out (FOMO) akin to social media. I felt pressured to keep following new blogs just like I am pressured to constantly &rsquo;like&rsquo; and &lsquo;follow&rsquo; new pages in traditional American social media.</p>
</li>
<li>
<p>there was a lot of context switching: many upstream RSS feeds aren&rsquo;t great, for example, by providing excerpts (summaries) only I&rsquo;d always have to visit the website directly if I wanted to read full articles. This doesn&rsquo;t scale well long term, attention is a precious resource and our brains aren&rsquo;t great at keeping steady and focused attention if we constantly context switch. A classical feed like this is <a href="http://www.aaronsw.com/2002/feeds/pgessays.rss">Paul Graham&rsquo;s</a>.</p>
</li>
<li>
<p>there was no ability to filter out (exclude) posts from feeds. For example, deleting posts with a certain title (Sponsor, Ad, some boring mainstream topic). A classical example is <a href="https://daringfireball.net/">John Gruber&rsquo;s Daring Fireball</a> sponsored posts which usually have &lsquo;Sponsor&rsquo; in their titles. Why do I have to manually skip these posts, why can&rsquo;t I teach my RSS reader to do it automatically for me?</p>
</li>
<li>
<p>lock-in: whenever I starred/saved posts that I liked for future reference, they would be stuck in the specific cloud provider I chose.</p>
</li>
</ul>
<p>These were some of my gripes.</p>
<p>During those years I had also tried to self-host <a href="https://tt-rss.org/">TinyTinyRSS</a> but it didn&rsquo;t really last for me:</p>
<ol>
<li>
<p>first, its stack is relatively bloated: hosting and maintaining a typical LAMP stack takes some considerable amount of effort — TinyTinyRSS requires a full PHP installation alongside a webserver (apache, nginx or similar) and a database. Suddenly there was a lot of complexity to maintain all that.</p>
</li>
<li>
<p>second, I didn&rsquo;t have any cloud resources (VPS), nor a local server in my home (e.g. a Raspberry Pi or a NUC or a NAS Appliance). An instance in my personal laptop wouldn&rsquo;t really scale either as I would have needed it to be always on if I wanted to have continuous access to it (e.g. from my phone).</p>
</li>
<li>
<p>third, I wasn&rsquo;t a seasoned sysadmin at the time and wasn&rsquo;t really looking forward to self-host.</p>
</li>
</ol>
<p>Then 2020 and the COVID-19 pandemic came along with all of its imposed
government lockdowns worldwide. Suddenly many people had a lot of free time on
their hands.</p>
<h2 id="self-hosting-at-home">Self-hosting at home</h2>
<p>Having an <a href="https://archlinux.org/">Arch Linux</a> workstation at home, it felt natural to try out Miniflux there first.</p>
<p>Miniflux has great upstream <a href="https://miniflux.app/docs/installation.html#debian">documentation</a> already, therefore it&rsquo;s just a matter of following it. It&rsquo;s out of scope of this post to duplicate the installation process here, however I will add a bit of color regarding my initial setup.</p>
<p><strong>Disclaimer</strong>: Those instructions will probably get out-of-date at some point.</p>
<p>Thankfully there&rsquo;s already a miniflux <a href="https://archlinux.org/packages/community/x86_64/miniflux/">package</a> for Arch, making my job much easier. Installing miniflux alone isn&rsquo;t enough though, we will also need to install a database server (PostgreSQL):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>$ sudo pacman -Syu miniflux postgresql
</span></span></code></pre></div><p>The next step is to configure the PostgreSQL server. Refer to the upstream documentation for that, but the TL;DR is:</p>
<ul>
<li>create a <code>miniflux</code> user</li>
<li>create a <code>miniflux</code> database owned by the <code>miniflux</code> user</li>
<li>perform a few tweaks (extension hstore)</li>
</ul>
<p>Then configure miniflux:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>$ cat /etc/miniflux.conf
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Purge articles after a few days: These values are actually the default. Listed here just for reference.</span>
</span></span><span style="display:flex;"><span>CLEANUP_ARCHIVE_READ_DAYS<span style="color:#f92672">=</span><span style="color:#ae81ff">30</span>
</span></span><span style="display:flex;"><span>CLEANUP_ARCHIVE_UNREAD_DAYS<span style="color:#f92672">=</span><span style="color:#ae81ff">90</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Database configuration</span>
</span></span><span style="display:flex;"><span>DATABASE_URL<span style="color:#f92672">=</span>user<span style="color:#f92672">=</span>miniflux password<span style="color:#f92672">=</span>&lt;password&gt; dbname<span style="color:#f92672">=</span>miniflux sslmode<span style="color:#f92672">=</span>disable
</span></span><span style="display:flex;"><span>RUN_MIGRATIONS<span style="color:#f92672">=</span>yes
</span></span></code></pre></div><p>We will also need to create an admin user for miniflux with <code>miniflux --create-admin</code>.</p>
<p>Then we start the database server and miniflux:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>$ sudo systemctl enable --now postgresql miniflux
</span></span></code></pre></div><p>Afterwards it&rsquo;s just a matter of navigating to http://localhost:8080 and logging in with your newly created admin user.</p>
<p>Miniflux is a pleasure to use, and it&rsquo;s very easy to get acquainted with it.</p>
<p>It&rsquo;s also possible to add custom CSS in its Settings. I added the following tweaks<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> for improved typography:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-css" data-lang="css"><span style="display:flex;"><span>:<span style="color:#a6e22e">root</span> {
</span></span><span style="display:flex;"><span>  --system-font-family: system-ui, <span style="color:#f92672">-</span>apple-system, BlinkMacSystemFont, <span style="color:#e6db74">&#34;Segoe UI&#34;</span>, Roboto, Helvetica, Arial, <span style="color:#e6db74">&#34;Noto Sans&#34;</span>, <span style="color:#66d9ef">sans-serif</span>, <span style="color:#e6db74">&#34;Apple Color Emoji&#34;</span>, <span style="color:#e6db74">&#34;Segoe UI Emoji&#34;</span>, <span style="color:#e6db74">&#34;Segoe UI Symbol&#34;</span>, <span style="color:#e6db74">&#34;Noto Color Emoji&#34;</span>;
</span></span><span style="display:flex;"><span>  --font-family: <span style="color:#a6e22e">var</span>(<span style="color:#f92672">--</span>system<span style="color:#f92672">-</span>font<span style="color:#f92672">-</span>family);
</span></span><span style="display:flex;"><span>  --entry-content-font-family: <span style="color:#a6e22e">var</span>(<span style="color:#f92672">--</span>system<span style="color:#f92672">-</span>font<span style="color:#f92672">-</span>family);
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">body</span> {
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">max-width</span>: <span style="color:#ae81ff">900</span><span style="color:#66d9ef">px</span>;
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">textarea</span><span style="color:#f92672">[</span><span style="color:#f92672">name</span><span style="color:#f92672">=</span><span style="color:#e6db74">&#34;custom_css&#34;</span><span style="color:#f92672">]</span> {
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">min-height</span>: <span style="color:#ae81ff">300</span><span style="color:#66d9ef">px</span>;
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">width</span>: <span style="color:#66d9ef">-webkit-</span><span style="color:#66d9ef">fill</span><span style="color:#f92672">-</span>available;
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p><strong>Update(2022-02-18)</strong>: It turns out the CSS above isn&rsquo;t really needed as a system font stack is set out-of-the-box.</p>
<p>The one main limitation of running Miniflux this way is that you&rsquo;ll need your workstation to be always on if you want to have continuous access to it. This means if you want to read late at night you&rsquo;ll need to leave your computer on. Not only this is impractical and inconvenient, it&rsquo;s also not much environmentally friendly.</p>
<p>Another limitation is that in principle you&rsquo;ll only be able to access Miniflux from home, unless you take extra measures<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> to make your workstation accessible from outside your home network.</p>
<h2 id="other-resources">Other resources</h2>
<p>Miniflux clients:</p>
<ul>
<li><strong>Miniflux web app</strong> (PWA), works well enough</li>
<li><a href="https://apps.apple.com/us/app/unread-an-rss-reader/id1363637349">Unread</a> (iOS) via Fever API, gesture based</li>
<li><a href="https://reederapp.com/">Reeder</a> (iOS) via Fever API</li>
<li><a href="https://newsboat.org/releases/2.21/docs/newsboat.html#_miniflux">newsboat</a> (CLI)</li>
</ul>
<p>Common self-hosted alternatives to miniflux:</p>
<ul>
<li><a href="https://freshrss.org/">FreshRSS</a></li>
<li><a href="https://tt-rss.org/">TinyTinyRSS</a></li>
<li><a href="https://feedbin.com/">Feedbin</a> (harder to self-host)</li>
</ul>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p><a href="https://kevq.uk/please-add-rss-support-to-your-site/">https://kevq.uk/please-add-rss-support-to-your-site/</a>&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p><a href="https://laurakalbag.com/subscribe/">https://laurakalbag.com/subscribe/</a>&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p><a href="https://css-tricks.com/snippets/css/system-font-stack/">https://css-tricks.com/snippets/css/system-font-stack/</a>&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>for example: a VPN like OpenVPN, <a href="https://www.wireguard.com/">Wireguard</a> or <a href="https://tailscale.com/">tailscale</a>; or a tool like <a href="https://ngrok.com/">ngrok</a>.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>]]></content:encoded></item><item><title>Ufw: Firewall</title><link>https://www.perrotta.dev/2021/12/ufw-firewall/</link><pubDate>Tue, 28 Dec 2021 17:14:55 -0500</pubDate><guid>https://www.perrotta.dev/2021/12/ufw-firewall/</guid><description>&lt;blockquote>
&lt;p>Ufw stands for Uncomplicated Firewall, and is a program for managing a netfilter firewall. It provides a command line interface and aims to be uncomplicated and easy to use.&lt;/p>
&lt;/blockquote></description><content:encoded><![CDATA[<blockquote>
<p>Ufw stands for Uncomplicated Firewall, and is a program for managing a netfilter firewall. It provides a command line interface and aims to be uncomplicated and easy to use.</p>
</blockquote>
<p>The firewall makes justice to its name as it is really uncomplicated, and a pleasure to set up.</p>
<h2 id="install">Install</h2>
<p>Install and set up <code>ufw</code><sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>, which should be packaged for most linux
distributions:</p>
<h3 id="openrc-based-alpine-linux-gentoo">OpenRC-based (Alpine Linux, Gentoo)</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#75715e"># Install ufw and ufw-extras</span>
</span></span><span style="display:flex;"><span>$ doas apk install ufw<span style="color:#f92672">{</span>,-extras<span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Enable ufw daemon</span>
</span></span><span style="display:flex;"><span>$ doas rc-update add ufw
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Start ufw daemon</span>
</span></span><span style="display:flex;"><span>$ doas rc-service ufw start
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Enable firewall</span>
</span></span><span style="display:flex;"><span>$ doas ufw enable
</span></span></code></pre></div><h3 id="systemd-based-arch-linux-debian">Systemd-based (Arch Linux, Debian)</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#75715e"># Install ufw and ufw-extras</span>
</span></span><span style="display:flex;"><span>$ sudo pacman -Syu ufw<span style="color:#f92672">{</span>,-extras<span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Enable and start ufw daemon</span>
</span></span><span style="display:flex;"><span>$ sudo systemctl enable --now ufw
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Enable firewall</span>
</span></span><span style="display:flex;"><span>$ sudo ufw enable
</span></span></code></pre></div><h2 id="add-rules">Add rules</h2>
<p>Firewall rules can be added with <code>ufw allow [port]</code> or <code>ufw allow [name]</code>.
Named profiles (for example: ssh, http) live in <code>/etc/ufw/applications.d/</code>, or you can query all of them with <code>ufw app list</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>% ufw app list
</span></span><span style="display:flex;"><span>Available applications:
</span></span><span style="display:flex;"><span>  AIM
</span></span><span style="display:flex;"><span>  Bonjour
</span></span><span style="display:flex;"><span>  CIFS
</span></span><span style="display:flex;"><span>  DNS
</span></span><span style="display:flex;"><span>  Deluge
</span></span><span style="display:flex;"><span>  IMAP
</span></span><span style="display:flex;"><span>  IMAPS
</span></span><span style="display:flex;"><span>  IPP
</span></span><span style="display:flex;"><span>  KTorrent
</span></span><span style="display:flex;"><span>  Kerberos Admin
</span></span><span style="display:flex;"><span>  Kerberos Full
</span></span><span style="display:flex;"><span>  Kerberos KDC
</span></span><span style="display:flex;"><span>  Kerberos Password
</span></span><span style="display:flex;"><span>  LDAP
</span></span><span style="display:flex;"><span>  LDAPS
</span></span><span style="display:flex;"><span>  LPD
</span></span><span style="display:flex;"><span>  MSN
</span></span><span style="display:flex;"><span>  MSN SSL
</span></span><span style="display:flex;"><span>  Mail submission
</span></span><span style="display:flex;"><span>  NFS
</span></span><span style="display:flex;"><span>  POP3
</span></span><span style="display:flex;"><span>  POP3S
</span></span><span style="display:flex;"><span>  PeopleNearby
</span></span><span style="display:flex;"><span>  SMTP
</span></span><span style="display:flex;"><span>  SSH
</span></span><span style="display:flex;"><span>  Socks
</span></span><span style="display:flex;"><span>  Telnet
</span></span><span style="display:flex;"><span>  Transmission
</span></span><span style="display:flex;"><span>  Transparent Proxy
</span></span><span style="display:flex;"><span>  VNC
</span></span><span style="display:flex;"><span>  WWW
</span></span><span style="display:flex;"><span>  WWW Cache
</span></span><span style="display:flex;"><span>  WWW Full
</span></span><span style="display:flex;"><span>  WWW Secure
</span></span><span style="display:flex;"><span>  XMPP
</span></span><span style="display:flex;"><span>  Yahoo
</span></span><span style="display:flex;"><span>  qBittorrent
</span></span><span style="display:flex;"><span>  svnserve
</span></span></code></pre></div><p>Ufw also supports <code>ufw limit [port | name]</code> which is like <code>add</code> but with the
added ability to &ldquo;deny connections from IP addresses that attempt to initiate
6 or more connections in the last 30 seconds&rdquo;. It&rsquo;s a good measure to mitigate brute-force and/or DDOS attacks.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#75715e"># either use named profiles</span>
</span></span><span style="display:flex;"><span>% ufw allow http-alt
</span></span><span style="display:flex;"><span>% ufw limit ssh
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># or port numbers</span>
</span></span><span style="display:flex;"><span>% ufw allow 8080/tcp
</span></span><span style="display:flex;"><span>% ufw limit <span style="color:#ae81ff">22</span>
</span></span></code></pre></div><h2 id="remove-rules">Remove rules</h2>
<p>Firewall rules can be removed by merely adding &lsquo;delete&rsquo; between ufw and the verb.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>% ufw delete allow 8080/tcp
</span></span><span style="display:flex;"><span>% ufw delete limit ssh
</span></span></code></pre></div><h2 id="check-status">Check status</h2>
<p>One status command to rule them all, &ldquo;verbose&rdquo; is optional:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>% ufw status verbose
</span></span><span style="display:flex;"><span>Status: active
</span></span><span style="display:flex;"><span>Logging: on <span style="color:#f92672">(</span>low<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>Default: deny <span style="color:#f92672">(</span>incoming<span style="color:#f92672">)</span>, allow <span style="color:#f92672">(</span>outgoing<span style="color:#f92672">)</span>, disabled <span style="color:#f92672">(</span>routed<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>New profiles: skip
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>To                         Action      From
</span></span><span style="display:flex;"><span>--                         ------      ----
</span></span><span style="display:flex;"><span>22/tcp                     LIMIT IN    Anywhere
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">8080</span>                       ALLOW IN    Anywhere
</span></span><span style="display:flex;"><span>22/tcp <span style="color:#f92672">(</span>v6<span style="color:#f92672">)</span>                LIMIT IN    Anywhere <span style="color:#f92672">(</span>v6<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">8080</span> <span style="color:#f92672">(</span>v6<span style="color:#f92672">)</span>                  ALLOW IN    Anywhere <span style="color:#f92672">(</span>v6<span style="color:#f92672">)</span>
</span></span></code></pre></div><p>Ufw uses iptables under the hood. Inspect the underlying iptables rules:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>% iptables -S | egrep <span style="color:#e6db74">&#39;\b(22|8080)\b&#39;</span>
</span></span><span style="display:flex;"><span>-A ufw-user-input -p tcp -m tcp --dport <span style="color:#ae81ff">22</span> -m conntrack --ctstate NEW -m recent --set --name DEFAULT --mask 255.255.255.255 --rsource
</span></span><span style="display:flex;"><span>-A ufw-user-input -p tcp -m tcp --dport <span style="color:#ae81ff">22</span> -m conntrack --ctstate NEW -m recent --update --seconds <span style="color:#ae81ff">30</span> --hitcount <span style="color:#ae81ff">6</span> --name DEFAULT --mask 255.255.255.255 --rsource -j ufw-user-limit
</span></span><span style="display:flex;"><span>-A ufw-user-input -p tcp -m tcp --dport <span style="color:#ae81ff">22</span> -j ufw-user-limit-accept
</span></span><span style="display:flex;"><span>-A ufw-user-input -p tcp -m tcp --dport <span style="color:#ae81ff">8080</span> -j ACCEPT
</span></span></code></pre></div><h2 id="references">References</h2>
<ul>
<li><a href="https://help.ubuntu.com/community/UFW">https://help.ubuntu.com/community/UFW</a></li>
<li><a href="https://wiki.archlinux.org/title/Uncomplicated_Firewall">https://wiki.archlinux.org/title/Uncomplicated_Firewall</a></li>
</ul>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p><a href="https://github.com/xyproto/ufw-extras"><code>ufw-extras</code></a> is optional, it contains additional rules (e.g. mosh, tailscale).&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>]]></content:encoded></item></channel></rss>