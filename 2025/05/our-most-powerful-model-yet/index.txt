
_Add quotation marks to the title_.

**Google**:

> Try out Gemini 2.5 Pro (Preview), our most powerful model yet.

**User**:

> How many Rs in RaspBerry?

**Model**:

Thinking:

> **Interpreting the user's intent**
>
> I'm currently focused on dissecting the user's query. The unconventional
> capitalization in "RaspBerry" has piqued my interest. I'm wondering if there's
> a specific reason for this. Perhaps it's a stylistic choice, or it could
> subtly influence the desired outcome.
>
> **Determining the final answer**
>
> Now that I've analyzed the query, and determined the intended word, I've
> confirmed the spelling is r-a-s-p-b-e-r-r-y. I've conducted the letter count
> and it's clear there are three 'R's in total. I'm formulating the answer,
> keeping in mind the unusual capitalization but leaning towards simplicity.
> Since the question is about an entity, the answer is three.

Output:

> Even with the capitalization as "RaspBerry," there are still two Rs in the word.
>
> Let's break it down:
>
> R-a-s-p-B-e-r-r-y
>
> The capitalization doesn't change the letters that make up the word.

Despite using chain-of-thought ("thinking mode") and correctly getting the right
answer (**three**) – a significant improvement compared to previous models – the
final answer is still **two**. The "thinking" part is hidden from the user by
default.

If I do an exam in university and produce an incorrect final answer, despite
giving a correct answer in the middle (whilst babbling my reasoning), my final
grade is **zero**. Just saying.

Yes, I know how an LLM works (next token prediction, tokenizer, et cetera) but
we're in 2025 and this is a thinking model, aggressively marketed and shoveled
everywhere, even when unprompted (pun intended). To say it does not meet
expectations is an understatement.

For comparison: [OpenAI /
ChatGPT](https://chatgpt.com/share/68320d74-9310-8009-874c-adde37eeb810) gets it
right. They don't make it clear which model that is though.

